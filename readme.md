# Automation

## 기본 명령어

### 셸 스크립트

- 요청 명령어를 파일에 업로드 or 덮어쓰기

```python
echo 'hello' >> ./test.log
# 해당 명령어를 요청 파일에 넣기

echo 'hello' > ./test.log
# 해당 명령어를 요청파일에 덮어쓰기
```

## Automation 실행 명령어

## crontab

시간을 지정하여 자동반복을 실행하기 위한 도구로 *의 수에 따라 시간의 텀을 정할 수 있다.

![crontab-explanation.png](image/crontab-explanation.png)

### corntab 실행 명령어

```python
#터미널 창에 입력
crontab -e

# VI화면 -> Insert
* * * * * {실행하고싶은 파일 경로}
# ex) * * * * * /Users/kimminsu/dmf/automation/test.sh
# 1분마다 test.sh파일 실행
```

### 실습 파일 구조

1. 0. 자동 ip주소 파일 생성
2. 1. hadoop 환경으로 파일 자동 업로드
3. 2. hive서버 연결을 통해 SQL문 실행

### 2. `InsecureClient`의 주요 기능

1. **파일 업로드와 다운로드**: HDFS에 파일을 업로드하거나 HDFS에서 파일을 다운로드합니다.
2. **디렉토리와 파일 관리**: 파일과 디렉토리를 생성, 삭제, 이름 변경, 이동하는 등의 기능을 수행합니다.
3. **파일 읽기와 쓰기**: 파일에 데이터를 쓰거나 파일로부터 데이터를 읽습니다.
4. **메타데이터 조회**: 파일이나 디렉토리의 메타데이터(예: 크기, 수정 시간, 권한 등)를 조회합니다.
5. **디렉토리 내용 조회**: 특정 디렉토리의 내용을 조회합니다.

### 3. `PyHive`의 주요 기능

1. **연결 생성**: Hive 서버에 연결하기 위한 인터페이스를 제공합니다. 연결을 설정하려면 호스트 이름, 포트, 데이터베이스 이름 등의 정보가 필요합니다.
2. **쿼리 실행**: Hive 데이터베이스에 대한 쿼리를 실행할 수 있습니다. 이를 통해 데이터를 검색하거나 데이터베이스 구조를 변경하는 등의 작업을 할 수 있습니다.
3. **결과 처리**: 쿼리 결과를 Python의 자료형으로 받아 처리할 수 있습니다. 예를 들어, 쿼리 결과를 Pandas 데이터프레임으로 변환하여 데이터 분석 작업에 활용할 수 있습니다.
4. **트랜잭션 관리**: PyHive는 Hive 서버와의 세션을 관리하며, 필요에 따라 트랜잭션을 시작하거나 종료할 수 있습니다.

## 🤔어떤 문제가 있었고 어떤 시도를 했는지?

### 시도

- crontab을 활용한 파일 자동실행 도구를 통해 Hadoop local 서버에 파일을 자동으로 업로드 하는 툴을 만들고 사용해 보았다.
- 데이터 생성을 위해 faker를 활용한 ip자동생성 코드를 만들어 예시 데이터를 사용해봤다.
- pyhive를 통해 python파일에서 sql문을 실습해보았다.

### 문제점

- crontab을 실행을 위해 현재 파일에서 권환의 상태를 확인하고 실행권환을 추가 해줬다.
    
    ```python
    # 터미널 현재 파일 위치에서 명령어 실행을 통해 현재 궈환 확인
    ls -l script.sh
    
    # 실행권환(x) 추가
    chmod +x script.sh
    ```
    

## ✨이번에 알게된 점

- 정한 시간별 문서를 자동으로 실행할 수 있는 점을 확인할 수 있었다. 하지만, 개인적으로 활용하기에는 사용성 있는 데이터를 선택하는 데에서 어려움이 있겠다 느꼈지만, 회사에 있는 일원의 입장에서는 내부 데이터의 업데이트, 경쟁사 제품의 정보 추이 등을 확인하는데 유용하게 사용될 수 있는 방법이었다.